{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8100113,"sourceType":"datasetVersion","datasetId":4783359},{"sourceId":8140388,"sourceType":"datasetVersion","datasetId":4812820}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-16T22:05:40.600279Z","iopub.execute_input":"2024-04-16T22:05:40.600618Z","iopub.status.idle":"2024-04-16T22:05:41.408858Z","shell.execute_reply.started":"2024-04-16T22:05:40.600590Z","shell.execute_reply":"2024-04-16T22:05:41.407932Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/election-dataset-2023-nig-pres/training_data_test.csv\n/kaggle/input/election-dataset-2023-nig-pres/training_data_updated.csv\n/kaggle/input/election-dataset-2023-nig-pres/test_data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport string\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:05:41.410639Z","iopub.execute_input":"2024-04-16T22:05:41.411128Z","iopub.status.idle":"2024-04-16T22:05:42.998933Z","shell.execute_reply.started":"2024-04-16T22:05:41.411101Z","shell.execute_reply":"2024-04-16T22:05:42.998021Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n  warnings.warn(\"The twython library has not been installed. \"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Download NLTK resources\nnltk.download('punkt')\nnltk.download('stopwords')\n\n# Read the dataset from CSV\ntrain_dataset = pd.read_csv(\"/kaggle/input/election-dataset-2023-nig-pres/training_data_updated.csv\")\n\n# Get the list of stopwords and punctuation\nstop_words = set(stopwords.words('english'))\npunctuation = set(string.punctuation)\n\n# Function to preprocess text and create tokens\ndef preprocess_text(text):\n    tokens = word_tokenize(text.lower())  # Tokenize and convert to lowercase\n    tokens = [word for word in tokens if word not in stop_words and word not in punctuation]  # Remove stopwords and punctuation\n    return tokens\n\n# Apply preprocessing and add tokens column\ntrain_dataset['tokens'] = train_dataset['preprocessed_text'].apply(preprocess_text)\n\n\n\n# Load the dataset from CSV\ntest_dataset = pd.read_csv(\"/kaggle/input/election-dataset-2023-nig-pres/training_data_test.csv\")\n\n# Get the list of stopwords and punctuation\nstop_words = set(stopwords.words('english'))\npunctuation = set(string.punctuation)\n\n# Function to preprocess text and create tokens\ndef preprocess_text(text):\n    tokens = word_tokenize(text.lower())  # Tokenize and convert to lowercase\n    tokens = [word for word in tokens if word not in stop_words and word not in punctuation]  # Remove stopwords and punctuation\n    return tokens\n\n# Apply preprocessing and add tokens column\ntest_dataset['tokens'] = test_dataset['preprocessed_text'].apply(preprocess_text)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:05:43.000005Z","iopub.execute_input":"2024-04-16T22:05:43.000419Z","iopub.status.idle":"2024-04-16T22:05:45.438927Z","shell.execute_reply.started":"2024-04-16T22:05:43.000392Z","shell.execute_reply":"2024-04-16T22:05:45.438119Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Print the updated dataset\nprint(train_dataset.head())","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:05:45.439988Z","iopub.execute_input":"2024-04-16T22:05:45.440287Z","iopub.status.idle":"2024-04-16T22:05:45.449617Z","shell.execute_reply.started":"2024-04-16T22:05:45.440263Z","shell.execute_reply":"2024-04-16T22:05:45.448743Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"                                   preprocessed_text candidate sentiment  \\\n0  user user but it won't work against obidatti t...       obi   neutral   \n1  just lol …..with all the thugs drama trying to...       obi  positive   \n2  i no see aduke name here o😂😂😂 , my sister chec...       obi   neutral   \n3  where are my warri obedients?obidatti2023 obid...       obi  positive   \n4  apc, lp, pdp and other political parties prote...   neutral   neutral   \n\n                                              tokens  \n0  [user, user, wo, n't, work, obidatti, ticket, ...  \n1  [lol, …..with, thugs, drama, trying, rig, obi,...  \n2  [see, aduke, name, o😂😂😂, sister, check, name, ...  \n3  [warri, obedients, obidatti2023, obidatti, obi...  \n4  [apc, lp, pdp, political, parties, protest, us...  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Print the first few rows of the dataset\nprint(test_dataset.head())","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:05:45.452446Z","iopub.execute_input":"2024-04-16T22:05:45.452723Z","iopub.status.idle":"2024-04-16T22:05:45.461591Z","shell.execute_reply.started":"2024-04-16T22:05:45.452701Z","shell.execute_reply":"2024-04-16T22:05:45.460744Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"                                   preprocessed_text candidate  sentiment  \\\n0  user user but it won't work against obidatti t...       obi        NaN   \n1  just lol …..with all the thugs drama trying to...       obi        NaN   \n2  i no see aduke name here o😂😂😂 , my sister chec...       obi        NaN   \n3  where are my warri obedients?obidatti2023 obid...       obi        NaN   \n4  apc, lp, pdp and other political parties prote...   neutral        NaN   \n\n                                              tokens  \n0  [user, user, wo, n't, work, obidatti, ticket, ...  \n1  [lol, …..with, thugs, drama, trying, rig, obi,...  \n2  [see, aduke, name, o😂😂😂, sister, check, name, ...  \n3  [warri, obedients, obidatti2023, obidatti, obi...  \n4  [apc, lp, pdp, political, parties, protest, us...  \n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install vaderSentiment\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n\n# Instantiate VADER\nvader = SentimentIntensityAnalyzer()\n\n# Get the list of stopwords and punctuation\nstop_words = set(stopwords.words('english'))\npunctuation = set(string.punctuation)\n\n# Function to preprocess text and create tokens\ndef preprocess_text(text):\n    tokens = word_tokenize(text.lower())  # Tokenize and convert to lowercase\n    tokens = [word for word in tokens if word not in stop_words and word not in punctuation]  # Remove stopwords and punctuation\n    return tokens\n\n# Function to predict sentiment using VADER\ndef predict_sentiment(text):\n    scores = vader.polarity_scores(text)\n    if scores['compound'] > 0:\n        return 'positive'\n    elif scores['compound'] < 0:\n        return 'negative'\n    else:\n        return 'neutral'\n\n# Preprocess test data and predict sentiment using VADER\ntest_dataset['sentiment'] = test_dataset['tokens'].apply(predict_sentiment)\n\n# Compare predicted sentiment with actual sentiment from training dataset\naccuracy = accuracy_score(train_dataset['sentiment'], test_dataset['sentiment'])\nprint(\"Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:05:45.462788Z","iopub.execute_input":"2024-04-16T22:05:45.463532Z","iopub.status.idle":"2024-04-16T22:05:58.352357Z","shell.execute_reply.started":"2024-04-16T22:05:45.463503Z","shell.execute_reply":"2024-04-16T22:05:58.351296Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting vaderSentiment\n  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from vaderSentiment) (2.31.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (2024.2.2)\nDownloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: vaderSentiment\nSuccessfully installed vaderSentiment-3.3.2\nAccuracy: 0.5207142857142857\n","output_type":"stream"}]},{"cell_type":"code","source":"test_dataset.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:05:58.353827Z","iopub.execute_input":"2024-04-16T22:05:58.354137Z","iopub.status.idle":"2024-04-16T22:05:58.371833Z","shell.execute_reply.started":"2024-04-16T22:05:58.354106Z","shell.execute_reply":"2024-04-16T22:05:58.370942Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                   preprocessed_text candidate sentiment  \\\n0  user user but it won't work against obidatti t...       obi   neutral   \n1  just lol …..with all the thugs drama trying to...       obi   neutral   \n2  i no see aduke name here o😂😂😂 , my sister chec...       obi   neutral   \n3  where are my warri obedients?obidatti2023 obid...       obi   neutral   \n4  apc, lp, pdp and other political parties prote...   neutral   neutral   \n\n                                              tokens  \n0  [user, user, wo, n't, work, obidatti, ticket, ...  \n1  [lol, …..with, thugs, drama, trying, rig, obi,...  \n2  [see, aduke, name, o😂😂😂, sister, check, name, ...  \n3  [warri, obedients, obidatti2023, obidatti, obi...  \n4  [apc, lp, pdp, political, parties, protest, us...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>preprocessed_text</th>\n      <th>candidate</th>\n      <th>sentiment</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>user user but it won't work against obidatti t...</td>\n      <td>obi</td>\n      <td>neutral</td>\n      <td>[user, user, wo, n't, work, obidatti, ticket, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>just lol …..with all the thugs drama trying to...</td>\n      <td>obi</td>\n      <td>neutral</td>\n      <td>[lol, …..with, thugs, drama, trying, rig, obi,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i no see aduke name here o😂😂😂 , my sister chec...</td>\n      <td>obi</td>\n      <td>neutral</td>\n      <td>[see, aduke, name, o😂😂😂, sister, check, name, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>where are my warri obedients?obidatti2023 obid...</td>\n      <td>obi</td>\n      <td>neutral</td>\n      <td>[warri, obedients, obidatti2023, obidatti, obi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>apc, lp, pdp and other political parties prote...</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>[apc, lp, pdp, political, parties, protest, us...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW, get_linear_schedule_with_warmup\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:05:58.373855Z","iopub.execute_input":"2024-04-16T22:05:58.374125Z","iopub.status.idle":"2024-04-16T22:06:04.811587Z","shell.execute_reply.started":"2024-04-16T22:05:58.374103Z","shell.execute_reply":"2024-04-16T22:06:04.810600Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Load the test dataset from CSV\ntest_df = pd.read_csv(\"/kaggle/input/election-dataset-2023-nig-pres/test_data.csv\")\n\n# Apply preprocessing and add tokens column\ntest_df['tokens'] = test_df['preprocessed_text'].apply(preprocess_text)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:06:04.812868Z","iopub.execute_input":"2024-04-16T22:06:04.813439Z","iopub.status.idle":"2024-04-16T22:06:05.317433Z","shell.execute_reply.started":"2024-04-16T22:06:04.813398Z","shell.execute_reply":"2024-04-16T22:06:05.316680Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:06:05.318569Z","iopub.execute_input":"2024-04-16T22:06:05.318921Z","iopub.status.idle":"2024-04-16T22:06:05.331737Z","shell.execute_reply.started":"2024-04-16T22:06:05.318887Z","shell.execute_reply":"2024-04-16T22:06:05.330842Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                   preprocessed_text candidate  sentiment  \\\n0  some people don't deserve to be called agents ...       obi        NaN   \n1  i just arrived at the venue of the breakfast t...       obi        NaN   \n2  user thank you very much... we the obidatti wa...       obi        NaN   \n3  what's happening over there in the north? it's...       obi        NaN   \n4  abuja prophet don join road show for obidatti🔥...       obi        NaN   \n\n                                              tokens  \n0  [people, n't, deserve, called, agents, obidatt...  \n1  [arrived, venue, breakfast, town, hall, meetin...  \n2  [user, thank, much, ..., obidatti, wait, till,...  \n3  ['s, happening, north, 's, quiet, nigeriadecid...  \n4  [abuja, prophet, join, road, show, obidatti🔥, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>preprocessed_text</th>\n      <th>candidate</th>\n      <th>sentiment</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>some people don't deserve to be called agents ...</td>\n      <td>obi</td>\n      <td>NaN</td>\n      <td>[people, n't, deserve, called, agents, obidatt...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i just arrived at the venue of the breakfast t...</td>\n      <td>obi</td>\n      <td>NaN</td>\n      <td>[arrived, venue, breakfast, town, hall, meetin...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>user thank you very much... we the obidatti wa...</td>\n      <td>obi</td>\n      <td>NaN</td>\n      <td>[user, thank, much, ..., obidatti, wait, till,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what's happening over there in the north? it's...</td>\n      <td>obi</td>\n      <td>NaN</td>\n      <td>['s, happening, north, 's, quiet, nigeriadecid...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>abuja prophet don join road show for obidatti🔥...</td>\n      <td>obi</td>\n      <td>NaN</td>\n      <td>[abuja, prophet, join, road, show, obidatti🔥, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Remove leading and trailing spaces from the \"sentiment\" column\ntrain_dataset['sentiment'] = train_dataset['sentiment'].str.strip()\n\n# View unique values of the \"sentiment\" column\nunique_sentiments = train_dataset['sentiment'].unique()\nprint(unique_sentiments)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:06:05.332962Z","iopub.execute_input":"2024-04-16T22:06:05.333308Z","iopub.status.idle":"2024-04-16T22:06:05.347484Z","shell.execute_reply.started":"2024-04-16T22:06:05.333277Z","shell.execute_reply":"2024-04-16T22:06:05.346602Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"['neutral' 'positive' 'negative']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Count the unique number of labels in the 'sentiment' column\nunique_labels_count = train_dataset['sentiment'].value_counts()\n\n# Print the result\nprint(\"Unique Number of Labels in 'sentiment' Column:\")\nprint(unique_labels_count)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:06:05.348539Z","iopub.execute_input":"2024-04-16T22:06:05.348834Z","iopub.status.idle":"2024-04-16T22:06:05.363352Z","shell.execute_reply.started":"2024-04-16T22:06:05.348811Z","shell.execute_reply":"2024-04-16T22:06:05.362279Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Unique Number of Labels in 'sentiment' Column:\nsentiment\nneutral     2198\npositive    1860\nnegative     142\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the training function\ndef train_model(model, train_dataloader, optimizer, scheduler, device, epochs):\n    model.train()\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch + 1}/{epochs}\")\n        total_loss = 0\n        for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/Training\"):\n            batch = tuple(t.to(device) for t in batch)\n            inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n            optimizer.zero_grad()\n            outputs = model(**inputs)\n            loss = outputs.loss\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            scheduler.step()\n            total_loss += loss.item()\n        avg_train_loss = total_loss / len(train_dataloader)\n        print(f\"Training Loss: {avg_train_loss:.4f}\")\n\n\n# Preprocess the text data (assuming 'text' column contains text data)\ntexts = train_dataset['preprocessed_text'].tolist()\nlabels = train_dataset['sentiment'].tolist()\n\n# Map textual labels to numerical values\nlabel_map = {\"neutral\": 0, \"positive\": 1, \"negative\": 2}\nlabels = [label_map[label] for label in labels]\n\n# Tokenize the texts\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\nencoded_texts = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n\n# Convert labels to tensors\nlabels = torch.tensor(labels)\n\n# Create TensorDataset\ndataset = TensorDataset(encoded_texts['input_ids'], encoded_texts['attention_mask'], labels)\n\n# Create a DataLoader\ntrain_dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load pre-trained RoBERTa model\nmodel = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3)\nmodel.to(device)\n\n# Set hyperparameters\nepochs = 3\noptimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\ntotal_steps = len(train_dataloader) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n\n# Define output directory for trained model\noutput_dir = \"./output\"\n\n# Training arguments\ntraining_args = {\n    \"output_dir\": output_dir,\n    \"num_train_epochs\": epochs,\n    \"per_device_train_batch_size\": 32,\n    \"save_steps\": -1,  # Save checkpoints after each epoch\n    \"save_total_limit\": 1,  # Only keep one checkpoint\n}\n\n# Train the model\ntrain_model(model, train_dataloader, optimizer, scheduler, device, epochs)\n\n# Save the model\nmodel.save_pretrained(output_dir)\n\n# Optionally, provide feedback that the file was successfully loaded\nprint(\"Training dataset loaded successfully.\")\n\n# Optionally, provide feedback that the model was successfully saved\nprint(f\"Model saved to {output_dir}.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:06:05.364837Z","iopub.execute_input":"2024-04-16T22:06:05.365159Z","iopub.status.idle":"2024-04-16T22:10:27.965472Z","shell.execute_reply.started":"2024-04-16T22:06:05.365130Z","shell.execute_reply":"2024-04-16T22:10:27.964404Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4e0fb77992c43f79685b30a70649a10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad3d30085f594fff8fe03167cd77b703"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aeadf04a6c7b4bfb8271593fe5340348"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb5676d7571943bba5963cdde8a28ddf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3283506693584094b043fee97bb51555"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b141afec0298416d88e9e68160640720"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/Training: 100%|██████████| 132/132 [01:20<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.7128\nEpoch 2/3\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/Training: 100%|██████████| 132/132 [01:20<00:00,  1.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.5817\nEpoch 3/3\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/Training: 100%|██████████| 132/132 [01:20<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.5250\nTraining dataset loaded successfully.\nModel saved to ./output.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Remove leading and trailing spaces from the \"sentiment\" column\n#test_df['sentiment'] = test_df['sentiment'].str.strip()\n\n# View unique values of the \"sentiment\" column\nunique_sentiments = test_df['sentiment'].unique()\nprint(unique_sentiments)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:10:27.969664Z","iopub.execute_input":"2024-04-16T22:10:27.969962Z","iopub.status.idle":"2024-04-16T22:10:27.976789Z","shell.execute_reply.started":"2024-04-16T22:10:27.969936Z","shell.execute_reply":"2024-04-16T22:10:27.975865Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"[nan]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load pre-trained RoBERTa tokenizer\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n\n# Preprocess the text data\ntest_texts = test_df['preprocessed_text'].tolist()\n\n# Define batch size\nbatch_size = 32\n\n# Calculate the total number of batches\ntotal_batches = len(test_texts) // batch_size + (len(test_texts) % batch_size != 0)\n\n# Load the trained model\nmodel = RobertaForSequenceClassification.from_pretrained(\"/kaggle/working/output/\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval()\n\n# Lists to store predicted sentiments and indices\npredicted_sentiments = []\nbatch_indices = []\n\n# Iterate through batches\nfor i in range(total_batches):\n    # Get the start and end indices for the current batch\n    start_idx = i * batch_size\n    end_idx = min((i + 1) * batch_size, len(test_texts))\n    batch_texts = test_texts[start_idx:end_idx]\n\n    # Tokenize the batch\n    encoded_batch = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\")\n    encoded_batch = {key: value.to(device) for key, value in encoded_batch.items()}\n\n    # Perform inference on the batch\n    with torch.no_grad():\n        outputs = model(**encoded_batch)\n        logits = outputs.logits\n\n    # Get predicted labels\n    predicted_labels = torch.argmax(logits, dim=1).tolist()\n    predicted_sentiments.extend(predicted_labels)\n    batch_indices.extend(range(start_idx, end_idx))\n\n# Map numerical labels back to original sentiment labels\nlabel_map = {0: 'neutral', 1: 'positive', 2: 'negative'}\npredicted_sentiments = [label_map[label] for label in predicted_sentiments]\n\n# Add predicted sentiments to the test dataframe at the correct indices\ntest_df['sentiment'] = None  # Initialize the column with None values\nfor idx, sentiment in zip(batch_indices, predicted_sentiments):\n    test_df.at[idx, 'sentiment'] = sentiment\n\n# Save the dataframe with predicted sentiments to a new CSV file\ntest_df.to_csv(\"path_to_save_predicted_test_results.csv\", index=False)\n\nprint(\"Predictions saved successfully.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:10:27.978038Z","iopub.execute_input":"2024-04-16T22:10:27.978378Z","iopub.status.idle":"2024-04-16T22:10:32.225427Z","shell.execute_reply.started":"2024-04-16T22:10:27.978349Z","shell.execute_reply":"2024-04-16T22:10:32.224506Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Predictions saved successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Remove leading and trailing spaces from the \"sentiment\" column\n#test_df['sentiment'] = test_df['sentiment'].str.strip()\n\n# View unique values of the \"sentiment\" column\nunique_sentiments = test_df['sentiment'].unique()\nprint(unique_sentiments)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:10:32.226659Z","iopub.execute_input":"2024-04-16T22:10:32.227490Z","iopub.status.idle":"2024-04-16T22:10:32.233066Z","shell.execute_reply.started":"2024-04-16T22:10:32.227461Z","shell.execute_reply":"2024-04-16T22:10:32.232144Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"['positive' 'neutral']\n","output_type":"stream"}]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:10:32.234333Z","iopub.execute_input":"2024-04-16T22:10:32.234915Z","iopub.status.idle":"2024-04-16T22:10:32.249143Z","shell.execute_reply.started":"2024-04-16T22:10:32.234883Z","shell.execute_reply":"2024-04-16T22:10:32.248281Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                   preprocessed_text candidate sentiment  \\\n0  some people don't deserve to be called agents ...       obi  positive   \n1  i just arrived at the venue of the breakfast t...       obi   neutral   \n2  user thank you very much... we the obidatti wa...       obi  positive   \n3  what's happening over there in the north? it's...       obi   neutral   \n4  abuja prophet don join road show for obidatti🔥...       obi  positive   \n\n                                              tokens  \n0  [people, n't, deserve, called, agents, obidatt...  \n1  [arrived, venue, breakfast, town, hall, meetin...  \n2  [user, thank, much, ..., obidatti, wait, till,...  \n3  ['s, happening, north, 's, quiet, nigeriadecid...  \n4  [abuja, prophet, join, road, show, obidatti🔥, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>preprocessed_text</th>\n      <th>candidate</th>\n      <th>sentiment</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>some people don't deserve to be called agents ...</td>\n      <td>obi</td>\n      <td>positive</td>\n      <td>[people, n't, deserve, called, agents, obidatt...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i just arrived at the venue of the breakfast t...</td>\n      <td>obi</td>\n      <td>neutral</td>\n      <td>[arrived, venue, breakfast, town, hall, meetin...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>user thank you very much... we the obidatti wa...</td>\n      <td>obi</td>\n      <td>positive</td>\n      <td>[user, thank, much, ..., obidatti, wait, till,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what's happening over there in the north? it's...</td>\n      <td>obi</td>\n      <td>neutral</td>\n      <td>['s, happening, north, 's, quiet, nigeriadecid...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>abuja prophet don join road show for obidatti🔥...</td>\n      <td>obi</td>\n      <td>positive</td>\n      <td>[abuja, prophet, join, road, show, obidatti🔥, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\n\n# Load pre-trained RoBERTa tokenizer\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n\n# Preprocess the text data from the test dataset\n#test_texts = test_dataset['preprocessed_text'].tolist()\n\n# Define batch size\nbatch_size = 32\n\n# Calculate the total number of batches\ntotal_batches = len(test_texts) // batch_size + (len(test_texts) % batch_size != 0)\n\n# Load the trained model\nmodel = RobertaForSequenceClassification.from_pretrained(\"/kaggle/working/output/\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval()\n\n# Lists to store predicted sentiments\npredicted_sentiments = []\n\n# Iterate through batches\nfor i in range(total_batches):\n    # Get the start and end indices for the current batch\n    start_idx = i * batch_size\n    end_idx = min((i + 1) * batch_size, len(test_texts))\n    batch_texts = test_texts[start_idx:end_idx]\n\n    # Tokenize the batch\n    encoded_batch = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\")\n    encoded_batch = {key: value.to(device) for key, value in encoded_batch.items()}\n\n    # Perform inference on the batch\n    with torch.no_grad():\n        outputs = model(**encoded_batch)\n        logits = outputs.logits\n\n    # Get predicted labels\n    predicted_labels = torch.argmax(logits, dim=1).tolist()\n    predicted_sentiments.extend(predicted_labels)\n\n# Map numerical labels back to original sentiment labels\nlabel_map = {0: 'neutral', 1: 'positive', 2: 'negative'}\npredicted_sentiments = [label_map[label] for label in predicted_sentiments]\n\n# Get true sentiments from the test dataset\ntrue_sentiments = test_df['sentiment'].tolist()\n\n# Ensure that the lengths of true_sentiments and predicted_sentiments are the same\nif len(true_sentiments) != len(predicted_sentiments):\n    raise ValueError(\"Number of samples in true_sentiments and predicted_sentiments lists do not match.\")\n\n# Calculate accuracy and F1 score\naccuracy = accuracy_score(true_sentiments, predicted_sentiments)\nf1 = f1_score(true_sentiments, predicted_sentiments, average='macro')\n\nprint(\"Accuracy:\", accuracy)\nprint(\"F1 Score:\", f1)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:10:32.250358Z","iopub.execute_input":"2024-04-16T22:10:32.250684Z","iopub.status.idle":"2024-04-16T22:10:36.433242Z","shell.execute_reply.started":"2024-04-16T22:10:32.250655Z","shell.execute_reply":"2024-04-16T22:10:36.432353Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Accuracy: 1.0\nF1 Score: 1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"test_dataset.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:10:36.434415Z","iopub.execute_input":"2024-04-16T22:10:36.434702Z","iopub.status.idle":"2024-04-16T22:10:36.447345Z","shell.execute_reply.started":"2024-04-16T22:10:36.434679Z","shell.execute_reply":"2024-04-16T22:10:36.446428Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                                   preprocessed_text candidate sentiment  \\\n0  user user but it won't work against obidatti t...       obi   neutral   \n1  just lol …..with all the thugs drama trying to...       obi   neutral   \n2  i no see aduke name here o😂😂😂 , my sister chec...       obi   neutral   \n3  where are my warri obedients?obidatti2023 obid...       obi   neutral   \n4  apc, lp, pdp and other political parties prote...   neutral   neutral   \n\n                                              tokens  \n0  [user, user, wo, n't, work, obidatti, ticket, ...  \n1  [lol, …..with, thugs, drama, trying, rig, obi,...  \n2  [see, aduke, name, o😂😂😂, sister, check, name, ...  \n3  [warri, obedients, obidatti2023, obidatti, obi...  \n4  [apc, lp, pdp, political, parties, protest, us...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>preprocessed_text</th>\n      <th>candidate</th>\n      <th>sentiment</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>user user but it won't work against obidatti t...</td>\n      <td>obi</td>\n      <td>neutral</td>\n      <td>[user, user, wo, n't, work, obidatti, ticket, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>just lol …..with all the thugs drama trying to...</td>\n      <td>obi</td>\n      <td>neutral</td>\n      <td>[lol, …..with, thugs, drama, trying, rig, obi,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i no see aduke name here o😂😂😂 , my sister chec...</td>\n      <td>obi</td>\n      <td>neutral</td>\n      <td>[see, aduke, name, o😂😂😂, sister, check, name, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>where are my warri obedients?obidatti2023 obid...</td>\n      <td>obi</td>\n      <td>neutral</td>\n      <td>[warri, obedients, obidatti2023, obidatti, obi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>apc, lp, pdp and other political parties prote...</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>[apc, lp, pdp, political, parties, protest, us...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:10:36.448366Z","iopub.execute_input":"2024-04-16T22:10:36.448627Z","iopub.status.idle":"2024-04-16T22:10:36.464031Z","shell.execute_reply.started":"2024-04-16T22:10:36.448605Z","shell.execute_reply":"2024-04-16T22:10:36.463184Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                   preprocessed_text candidate sentiment  \\\n0  some people don't deserve to be called agents ...       obi  positive   \n1  i just arrived at the venue of the breakfast t...       obi   neutral   \n2  user thank you very much... we the obidatti wa...       obi  positive   \n3  what's happening over there in the north? it's...       obi   neutral   \n4  abuja prophet don join road show for obidatti🔥...       obi  positive   \n\n                                              tokens  \n0  [people, n't, deserve, called, agents, obidatt...  \n1  [arrived, venue, breakfast, town, hall, meetin...  \n2  [user, thank, much, ..., obidatti, wait, till,...  \n3  ['s, happening, north, 's, quiet, nigeriadecid...  \n4  [abuja, prophet, join, road, show, obidatti🔥, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>preprocessed_text</th>\n      <th>candidate</th>\n      <th>sentiment</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>some people don't deserve to be called agents ...</td>\n      <td>obi</td>\n      <td>positive</td>\n      <td>[people, n't, deserve, called, agents, obidatt...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i just arrived at the venue of the breakfast t...</td>\n      <td>obi</td>\n      <td>neutral</td>\n      <td>[arrived, venue, breakfast, town, hall, meetin...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>user thank you very much... we the obidatti wa...</td>\n      <td>obi</td>\n      <td>positive</td>\n      <td>[user, thank, much, ..., obidatti, wait, till,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what's happening over there in the north? it's...</td>\n      <td>obi</td>\n      <td>neutral</td>\n      <td>['s, happening, north, 's, quiet, nigeriadecid...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>abuja prophet don join road show for obidatti🔥...</td>\n      <td>obi</td>\n      <td>positive</td>\n      <td>[abuja, prophet, join, road, show, obidatti🔥, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport torch\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification\nfrom sklearn.metrics import accuracy_score\n\n# Load test dataset\ntest_dataset = test_df\n#pd.read_csv(\"/kaggle/input/election-dataset-2023-nig-pres/test_data.csv\")\n\n# Define batch size for processing\nbatch_size = 32\n\n# Function to predict sentiment using VADER\ndef predict_sentiment_vader(texts):\n    analyzer = SentimentIntensityAnalyzer()\n    sentiments = []\n    for text in texts:\n        scores = analyzer.polarity_scores(text)\n        if scores['compound'] > 0:\n            sentiments.append('positive')\n        elif scores['compound'] < 0:\n            sentiments.append('negative')\n        else:\n            sentiments.append('neutral')\n    return sentiments\n\n# Function to predict sentiment using RoBERTa model\ndef predict_sentiment_roberta(texts):\n    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n    model = RobertaForSequenceClassification.from_pretrained(\"/kaggle/working/output/\")\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model.eval()\n    sentiments = []\n    for text in texts:\n        encoded_text = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n        encoded_text = {key: value.to(device) for key, value in encoded_text.items()}\n        with torch.no_grad():\n            outputs = model(**encoded_text)\n            logits = outputs.logits\n        predicted_label = torch.argmax(logits, dim=1).item()\n        label_map = {0: 'neutral', 1: 'positive', 2: 'negative'}\n        sentiments.append(label_map[predicted_label])\n    return sentiments\n\n# Predict sentiments using VADER in batches\nvader_sentiments = []\nfor i in range(0, len(test_dataset), batch_size):\n    batch_texts = test_dataset['preprocessed_text'].iloc[i:i+batch_size].tolist()\n    vader_sentiments.extend(predict_sentiment_vader(batch_texts))\n\n# Predict sentiments using RoBERTa in batches\nroberta_sentiments = []\nfor i in range(0, len(test_dataset), batch_size):\n    batch_texts = test_dataset['preprocessed_text'].iloc[i:i+batch_size].tolist()\n    roberta_sentiments.extend(predict_sentiment_roberta(batch_texts))\n\n# Function to ensemble predictions\ndef ensemble_predictions(vader_sentiment, roberta_sentiment):\n    if vader_sentiment == roberta_sentiment:\n        return vader_sentiment\n    else:\n        return 'neutral'  # Default to neutral if there's no majority\n\n# Add vader_sentiment and roberta_sentiment columns to the test dataset\ntest_dataset['vader_sentiment'] = vader_sentiments\ntest_dataset['roberta_sentiment'] = roberta_sentiments\n\n# Drop rows with missing values in the 'sentiment' column\ntest_dataset.dropna(subset=['sentiment'], inplace=True)\n\n# Ensemble predictions\ntest_dataset['ensemble_sentiment'] = test_dataset.apply(lambda x: ensemble_predictions(x['vader_sentiment'], x['roberta_sentiment']), axis=1)\n\n# Calculate accuracy\naccuracy = accuracy_score(test_dataset['sentiment'], test_dataset['ensemble_sentiment'])\nprint(\"Ensemble Model Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:10:36.465417Z","iopub.execute_input":"2024-04-16T22:10:36.465647Z","iopub.status.idle":"2024-04-16T22:11:32.469357Z","shell.execute_reply.started":"2024-04-16T22:10:36.465627Z","shell.execute_reply":"2024-04-16T22:11:32.468155Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Ensemble Model Accuracy: 0.7227777777777777\n","output_type":"stream"}]},{"cell_type":"code","source":"test_dataset.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:30:05.101123Z","iopub.execute_input":"2024-04-16T22:30:05.102080Z","iopub.status.idle":"2024-04-16T22:30:05.117466Z","shell.execute_reply.started":"2024-04-16T22:30:05.102048Z","shell.execute_reply":"2024-04-16T22:30:05.116410Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                   preprocessed_text candidate sentiment  \\\n0  some people don't deserve to be called agents ...       obi  positive   \n1  i just arrived at the venue of the breakfast t...       obi   neutral   \n2  user thank you very much... we the obidatti wa...       obi  positive   \n3  what's happening over there in the north? it's...       obi   neutral   \n4  abuja prophet don join road show for obidatti🔥...       obi  positive   \n\n                                              tokens vader_sentiment  \\\n0  [people, n't, deserve, called, agents, obidatt...         neutral   \n1  [arrived, venue, breakfast, town, hall, meetin...         neutral   \n2  [user, thank, much, ..., obidatti, wait, till,...        positive   \n3  ['s, happening, north, 's, quiet, nigeriadecid...         neutral   \n4  [abuja, prophet, join, road, show, obidatti🔥, ...        negative   \n\n  roberta_sentiment ensemble_sentiment  \n0          positive            neutral  \n1           neutral            neutral  \n2          positive           positive  \n3           neutral            neutral  \n4          positive            neutral  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>preprocessed_text</th>\n      <th>candidate</th>\n      <th>sentiment</th>\n      <th>tokens</th>\n      <th>vader_sentiment</th>\n      <th>roberta_sentiment</th>\n      <th>ensemble_sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>some people don't deserve to be called agents ...</td>\n      <td>obi</td>\n      <td>positive</td>\n      <td>[people, n't, deserve, called, agents, obidatt...</td>\n      <td>neutral</td>\n      <td>positive</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i just arrived at the venue of the breakfast t...</td>\n      <td>obi</td>\n      <td>neutral</td>\n      <td>[arrived, venue, breakfast, town, hall, meetin...</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>user thank you very much... we the obidatti wa...</td>\n      <td>obi</td>\n      <td>positive</td>\n      <td>[user, thank, much, ..., obidatti, wait, till,...</td>\n      <td>positive</td>\n      <td>positive</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what's happening over there in the north? it's...</td>\n      <td>obi</td>\n      <td>neutral</td>\n      <td>['s, happening, north, 's, quiet, nigeriadecid...</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>abuja prophet don join road show for obidatti🔥...</td>\n      <td>obi</td>\n      <td>positive</td>\n      <td>[abuja, prophet, join, road, show, obidatti🔥, ...</td>\n      <td>negative</td>\n      <td>positive</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}